<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evalyn Recipe - LLM Agent Evaluation Toolkit</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #1a1a1a;
            background: #fafafa;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 60px 20px;
            text-align: center;
            margin-bottom: 40px;
            border-radius: 12px;
        }

        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 700;
        }

        header p {
            font-size: 1.2em;
            opacity: 0.95;
        }

        .section {
            background: white;
            padding: 30px;
            margin-bottom: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        h2 {
            color: #667eea;
            margin-bottom: 20px;
            font-size: 1.8em;
            border-bottom: 2px solid #f0f0f0;
            padding-bottom: 10px;
        }

        h3 {
            color: #764ba2;
            margin-top: 25px;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .badge {
            display: inline-block;
            background: #667eea;
            color: white;
            padding: 4px 12px;
            border-radius: 12px;
            font-size: 0.85em;
            font-weight: 600;
            margin-left: 10px;
        }

        .code-block {
            position: relative;
            margin: 20px 0;
        }

        .code-header {
            background: #2d3748;
            color: #a0aec0;
            padding: 8px 15px;
            border-radius: 6px 6px 0 0;
            font-size: 0.9em;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .copy-btn {
            background: #4a5568;
            color: white;
            border: none;
            padding: 5px 12px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.85em;
            transition: background 0.2s;
        }

        .copy-btn:hover {
            background: #667eea;
        }

        .copy-btn.copied {
            background: #48bb78;
        }

        pre {
            background: #1a202c;
            color: #e2e8f0;
            padding: 20px;
            border-radius: 0 0 6px 6px;
            overflow-x: auto;
            font-size: 0.9em;
            line-height: 1.5;
        }

        code {
            font-family: 'Courier New', Courier, monospace;
        }

        .inline-code {
            background: #edf2f7;
            color: #667eea;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
        }

        .workflow {
            display: flex;
            align-items: center;
            margin: 20px 0;
            padding: 15px;
            background: #f7fafc;
            border-left: 4px solid #667eea;
            border-radius: 4px;
        }

        .workflow-number {
            background: #667eea;
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 1.2em;
            margin-right: 15px;
            flex-shrink: 0;
        }

        .workflow-content {
            flex: 1;
        }

        .workflow-title {
            font-weight: 600;
            color: #2d3748;
            margin-bottom: 5px;
        }

        .workflow-desc {
            color: #4a5568;
            font-size: 0.95em;
        }

        .tip {
            background: #fffaf0;
            border-left: 4px solid #ed8936;
            padding: 15px;
            margin: 20px 0;
            border-radius: 4px;
        }

        .tip-title {
            font-weight: 600;
            color: #c05621;
            margin-bottom: 5px;
        }

        .note {
            background: #e6fffa;
            border-left: 4px solid #38b2ac;
            padding: 15px;
            margin: 20px 0;
            border-radius: 4px;
        }

        .note-title {
            font-weight: 600;
            color: #234e52;
            margin-bottom: 5px;
        }

        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .card {
            background: #f7fafc;
            padding: 20px;
            border-radius: 6px;
            border: 1px solid #e2e8f0;
        }

        .card-title {
            font-weight: 600;
            color: #667eea;
            margin-bottom: 10px;
        }

        .card-desc {
            color: #4a5568;
            font-size: 0.95em;
        }

        ul {
            margin-left: 20px;
            margin-top: 10px;
        }

        li {
            margin: 8px 0;
            color: #4a5568;
        }

        footer {
            text-align: center;
            padding: 40px 20px;
            color: #718096;
            font-size: 0.9em;
        }

        a {
            color: #667eea;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üéØ Evalyn Recipe</h1>
            <p>Production-ready evaluation workflow for LLM agents</p>
        </header>

        <!-- Introduction -->
        <div class="section">
            <h2>What is Evalyn?</h2>
            <p>Evalyn is a Python SDK for instrumenting, tracing, and evaluating LLM agents. It provides:</p>
            <div class="grid">
                <div class="card">
                    <div class="card-title">üîç Automatic Tracing</div>
                    <div class="card-desc">Capture all agent interactions with a simple decorator</div>
                </div>
                <div class="card">
                    <div class="card-title">üìä Objective Metrics</div>
                    <div class="card-desc">Latency, cost, JSON validation, BLEU, ROUGE</div>
                </div>
                <div class="card">
                    <div class="card-title">ü§ñ LLM Judges</div>
                    <div class="card-desc">Subjective evaluation with prompt optimization</div>
                </div>
                <div class="card">
                    <div class="card-title">üéØ Human Calibration</div>
                    <div class="card-desc">Align AI judges with human preferences</div>
                </div>
            </div>
        </div>

        <!-- Quick Start -->
        <div class="section">
            <h2>Quick Start</h2>

            <h3>1. Installation</h3>
            <div class="code-block">
                <div class="code-header">
                    <span>bash</span>
                    <button class="copy-btn" onclick="copyCode(this, 'install')">Copy</button>
                </div>
                <pre id="install"><code>pip install -e ".[dev,llm,otel,agent]"

# Set your API key
export GEMINI_API_KEY="your-api-key-here"</code></pre>
            </div>

            <h3>2. Instrument Your Agent</h3>
            <div class="code-block">
                <div class="code-header">
                    <span>Python</span>
                    <button class="copy-btn" onclick="copyCode(this, 'instrument')">Copy</button>
                </div>
                <pre id="instrument"><code>from evalyn_sdk import eval

@eval(project="my-agent", version="v1")
def my_agent(query: str) -> str:
    """Your agent implementation."""
    # Call LLMs, use tools, etc.
    response = process_query(query)
    return response

# Run your agent - traces are captured automatically!
result = my_agent("What is the weather in SF?")</code></pre>
            </div>

            <div class="note">
                <div class="note-title">üìù Note</div>
                All function calls are automatically traced to <span class="inline-code">evalyn.sqlite</span> with inputs, outputs, duration, errors, and trace events.
            </div>
        </div>

        <!-- Core Workflow -->
        <div class="section">
            <h2>Complete Evaluation Workflow</h2>

            <div class="workflow">
                <div class="workflow-number">1</div>
                <div class="workflow-content">
                    <div class="workflow-title">Collect Traces</div>
                    <div class="workflow-desc">Run your agent with the @eval decorator</div>
                </div>
            </div>

            <div class="workflow">
                <div class="workflow-number">2</div>
                <div class="workflow-content">
                    <div class="workflow-title">Build Dataset</div>
                    <div class="workflow-desc">Convert traces into a test dataset</div>
                </div>
            </div>

            <div class="code-block">
                <div class="code-header">
                    <span>bash</span>
                    <button class="copy-btn" onclick="copyCode(this, 'build-dataset')">Copy</button>
                </div>
                <pre id="build-dataset"><code># Build dataset from traced calls
evalyn build-dataset --project my-agent --version v1 --limit 200

# Output: data/my-agent-v1-20250126/dataset.jsonl</code></pre>
            </div>

            <div class="workflow">
                <div class="workflow-number">3</div>
                <div class="workflow-content">
                    <div class="workflow-title">Select Metrics</div>
                    <div class="workflow-desc">Choose evaluation metrics (heuristic, LLM, or pre-configured)</div>
                </div>
            </div>

            <div class="code-block">
                <div class="code-header">
                    <span>bash</span>
                    <button class="copy-btn" onclick="copyCode(this, 'suggest-metrics')">Copy</button>
                </div>
                <pre id="suggest-metrics"><code># Fast heuristic suggestions (no LLM needed)
evalyn suggest-metrics --target agent.py:my_agent --mode basic

# LLM-powered selection from 50+ metric registry
evalyn suggest-metrics --target agent.py:my_agent \
  --mode llm-registry \
  --llm-mode api \
  --model gemini-2.5-flash

# Save to dataset
evalyn suggest-metrics --dataset data/my-agent-v1-20250126 \
  --target agent.py:my_agent \
  --mode llm-registry \
  --llm-mode api</code></pre>
            </div>

            <div class="workflow">
                <div class="workflow-number">4</div>
                <div class="workflow-content">
                    <div class="workflow-title">Run Evaluation</div>
                    <div class="workflow-desc">Execute metrics against your dataset</div>
                </div>
            </div>

            <div class="code-block">
                <div class="code-header">
                    <span>bash</span>
                    <button class="copy-btn" onclick="copyCode(this, 'run-eval')">Copy</button>
                </div>
                <pre id="run-eval"><code># Auto-detects metrics from dataset
evalyn run-eval --dataset data/my-agent-v1-20250126

# Or use --latest to auto-discover most recent dataset
evalyn run-eval --latest

# View results
evalyn list-runs
evalyn show-run --id <run_id></code></pre>
            </div>

            <div class="workflow">
                <div class="workflow-number">5</div>
                <div class="workflow-content">
                    <div class="workflow-title">Human Annotation</div>
                    <div class="workflow-desc">Label outputs to calibrate LLM judges</div>
                </div>
            </div>

            <div class="code-block">
                <div class="code-header">
                    <span>bash</span>
                    <button class="copy-btn" onclick="copyCode(this, 'annotate')">Copy</button>
                </div>
                <pre id="annotate"><code># Interactive annotation (shows LLM judge results)
evalyn annotate --dataset data/my-agent-v1-20250126

# Or use --latest
evalyn annotate --latest

# Per-metric annotation (agree/disagree with each metric)
evalyn annotate --dataset data/my-agent-v1-20250126 --per-metric</code></pre>
            </div>

            <div class="workflow">
                <div class="workflow-number">6</div>
                <div class="workflow-content">
                    <div class="workflow-title">Calibrate Judges</div>
                    <div class="workflow-desc">Optimize LLM judge prompts using human feedback</div>
                </div>
            </div>

            <div class="code-block">
                <div class="code-header">
                    <span>bash</span>
                    <button class="copy-btn" onclick="copyCode(this, 'calibrate')">Copy</button>
                </div>
                <pre id="calibrate"><code># LLM-based prompt optimization (fast)
evalyn calibrate \
  --metric-id helpfulness_accuracy \
  --annotations annotations.jsonl \
  --dataset data/my-agent-v1-20250126

# GEPA optimization (thorough, evolutionary search)
evalyn calibrate \
  --metric-id helpfulness_accuracy \
  --annotations annotations.jsonl \
  --dataset data/my-agent-v1-20250126 \
  --optimizer gepa \
  --gepa-max-calls 200</code></pre>
            </div>

            <div class="workflow">
                <div class="workflow-number">7</div>
                <div class="workflow-content">
                    <div class="workflow-title">Iterate & Improve</div>
                    <div class="workflow-desc">Use optimized prompts and expand test coverage</div>
                </div>
            </div>
        </div>

        <!-- Advanced Patterns -->
        <div class="section">
            <h2>Advanced Patterns</h2>

            <h3>Configuration File</h3>
            <p>Set defaults with <span class="inline-code">evalyn.yaml</span> or <span class="inline-code">.evalynrc</span>:</p>
            <div class="code-block">
                <div class="code-header">
                    <span>yaml</span>
                    <button class="copy-btn" onclick="copyCode(this, 'config')">Copy</button>
                </div>
                <pre id="config"><code># evalyn.yaml
default_dataset: data/my-agent-v1-20250126
default_model: gemini-2.5-flash
default_limit: 50</code></pre>
            </div>

            <h3>Programmatic Usage</h3>
            <div class="code-block">
                <div class="code-header">
                    <span>Python</span>
                    <button class="copy-btn" onclick="copyCode(this, 'programmatic')">Copy</button>
                </div>
                <pre id="programmatic"><code>from evalyn_sdk import (
    load_dataset,
    EvalRunner,
    build_objective_metric,
    build_subjective_metric,
    load_optimized_prompt,
)

# Load dataset
items = load_dataset("data/my-agent-v1/dataset.jsonl")

# Create metrics
metrics = [
    build_objective_metric("latency_ms"),
    build_objective_metric("json_valid"),
    build_subjective_metric("helpfulness_accuracy"),
]

# Run evaluation
runner = EvalRunner(target=my_agent, metrics=metrics)
run = runner.run(items)

# Load optimized prompt for a metric
prompt = load_optimized_prompt(
    "data/my-agent-v1",
    "helpfulness_accuracy"
)</code></pre>
            </div>

            <h3>Synthetic Data Generation</h3>
            <div class="code-block">
                <div class="code-header">
                    <span>bash</span>
                    <button class="copy-btn" onclick="copyCode(this, 'simulate')">Copy</button>
                </div>
                <pre id="simulate"><code># Generate synthetic queries from seed dataset
evalyn simulate --dataset data/my-agent-v1 --modes similar,outlier

# Generate and run through agent (full pipeline)
evalyn simulate \
  --dataset data/my-agent-v1 \
  --target agent.py:my_agent \
  --num-similar 10 \
  --num-outlier 5</code></pre>
            </div>

            <h3>Utility Commands</h3>
            <div class="code-block">
                <div class="code-header">
                    <span>bash</span>
                    <button class="copy-btn" onclick="copyCode(this, 'utility')">Copy</button>
                </div>
                <pre id="utility"><code># Quick status overview
evalyn status

# List all calibrations
evalyn list-calibrations
evalyn list-calibrations --dataset data/my-agent-v1

# View available metric templates
evalyn list-metrics

# View captured traces
evalyn list-calls --limit 20
evalyn show-call --id <call_id></code></pre>
            </div>
        </div>

        <!-- Metric Selection Guide -->
        <div class="section">
            <h2>Metric Selection Guide</h2>

            <h3>Objective Metrics (No LLM)</h3>
            <ul>
                <li><span class="inline-code">latency_ms</span> - Response time</li>
                <li><span class="inline-code">cost</span> - API costs</li>
                <li><span class="inline-code">json_valid</span> - JSON format validation</li>
                <li><span class="inline-code">token_length</span> - Output length constraints</li>
                <li><span class="inline-code">tool_call_count</span> - Number of tool invocations</li>
                <li><span class="inline-code">bleu</span>, <span class="inline-code">rouge_l</span> - Text similarity (requires reference)</li>
            </ul>

            <h3>Subjective Metrics (LLM Judge)</h3>
            <ul>
                <li><span class="inline-code">helpfulness_accuracy</span> - Response quality</li>
                <li><span class="inline-code">toxicity_safety</span> - Safety violations</li>
                <li><span class="inline-code">hallucination_risk</span> - Factual accuracy</li>
                <li><span class="inline-code">completeness</span> - Thorough responses</li>
                <li><span class="inline-code">tone_professionalism</span> - Communication style</li>
                <li><span class="inline-code">instruction_following</span> - Task adherence</li>
            </ul>

            <div class="tip">
                <div class="tip-title">üí° Tip</div>
                Start with <span class="inline-code">--mode basic</span> for fast suggestions, then use <span class="inline-code">--mode llm-registry</span> for production. Pre-configured bundles are available: <span class="inline-code">summarization</span>, <span class="inline-code">orchestrator</span>, <span class="inline-code">research-agent</span>.
            </div>
        </div>

        <!-- Best Practices -->
        <div class="section">
            <h2>Best Practices</h2>

            <div class="grid">
                <div class="card">
                    <div class="card-title">üì¶ Version Everything</div>
                    <div class="card-desc">Use <span class="inline-code">project</span> and <span class="inline-code">version</span> in @eval decorator to track changes over time</div>
                </div>
                <div class="card">
                    <div class="card-title">üéØ Start Simple</div>
                    <div class="card-desc">Begin with objective metrics, add LLM judges for quality assessment</div>
                </div>
                <div class="card">
                    <div class="card-title">üë• Calibrate Early</div>
                    <div class="card-desc">Annotate 20-50 samples to align LLM judges with your standards</div>
                </div>
                <div class="card">
                    <div class="card-title">üîÑ Iterate Quickly</div>
                    <div class="card-desc">Use <span class="inline-code">--latest</span> flag for rapid experimentation</div>
                </div>
            </div>

            <h3>Prompt Optimization Strategy</h3>
            <ul>
                <li><strong>LLM optimizer</strong> (<span class="inline-code">--optimizer llm</span>): Fast single-pass optimization, good for quick iterations</li>
                <li><strong>GEPA optimizer</strong> (<span class="inline-code">--optimizer gepa</span>): Evolutionary search, more thorough but requires more API calls</li>
                <li>GEPA only optimizes the preamble; rubric (human-defined criteria) stays fixed</li>
                <li>Use <span class="inline-code">--gepa-max-calls</span> to control budget (default: 150)</li>
            </ul>
        </div>

        <!-- Dataset Structure -->
        <div class="section">
            <h2>Dataset Structure</h2>
            <div class="code-block">
                <div class="code-header">
                    <span>File Structure</span>
                    <button class="copy-btn" onclick="copyCode(this, 'structure')">Copy</button>
                </div>
                <pre id="structure"><code>data/my-agent-v1-20250126/
  dataset.jsonl              # Test cases
  meta.json                  # Dataset metadata
  metrics/
    llm-registry-*.json      # LLM-selected metrics
    basic-*.json             # Heuristic metrics
  eval_runs/
    <timestamp>_<id>.json    # Evaluation results
  calibrations/
    helpfulness_accuracy/
      <timestamp>_gepa.json  # Calibration record
      prompts/
        <timestamp>_full.txt # Optimized prompt</code></pre>
            </div>
        </div>

        <!-- Common Issues -->
        <div class="section">
            <h2>Troubleshooting</h2>

            <h3>Missing API Key</h3>
            <div class="code-block">
                <div class="code-header">
                    <span>bash</span>
                    <button class="copy-btn" onclick="copyCode(this, 'api-key')">Copy</button>
                </div>
                <pre id="api-key"><code># For Gemini (recommended)
export GEMINI_API_KEY="your-key"

# For OpenAI
export OPENAI_API_KEY="your-key"

# Verify it's set
echo $GEMINI_API_KEY</code></pre>
            </div>

            <h3>GEPA Not Installed</h3>
            <div class="code-block">
                <div class="code-header">
                    <span>bash</span>
                    <button class="copy-btn" onclick="copyCode(this, 'install-gepa')">Copy</button>
                </div>
                <pre id="install-gepa"><code>pip install gepa</code></pre>
            </div>

            <h3>No Traces Found</h3>
            <p>Make sure you've:</p>
            <ul>
                <li>Added <span class="inline-code">@eval</span> decorator to your function</li>
                <li>Actually called the decorated function</li>
                <li>Checked the right project/version with <span class="inline-code">evalyn show-projects</span></li>
            </ul>
        </div>

        <!-- Quick Reference -->
        <div class="section">
            <h2>Quick Reference</h2>
            <div class="code-block">
                <div class="code-header">
                    <span>Cheat Sheet</span>
                    <button class="copy-btn" onclick="copyCode(this, 'cheatsheet')">Copy</button>
                </div>
                <pre id="cheatsheet"><code># Essential Commands
evalyn status                           # Overview
evalyn build-dataset --project X --version Y
evalyn suggest-metrics --target file.py:func --mode basic
evalyn run-eval --latest
evalyn annotate --latest
evalyn calibrate --metric-id X --annotations ann.jsonl --latest
evalyn list-calibrations

# View Data
evalyn list-calls --limit 20
evalyn list-runs
evalyn show-run --id <id>
evalyn list-metrics

# Simulate
evalyn simulate --dataset data/X --modes similar,outlier</code></pre>
            </div>
        </div>
    </div>

    <footer>
        <p>Built with ‚ù§Ô∏è for developers evaluating LLM agents</p>
        <p>See <a href="../CLAUDE.md">CLAUDE.md</a> for comprehensive documentation</p>
    </footer>

    <script>
        function copyCode(button, elementId) {
            const codeElement = document.getElementById(elementId);
            const code = codeElement.textContent;

            navigator.clipboard.writeText(code).then(() => {
                const originalText = button.textContent;
                button.textContent = 'Copied!';
                button.classList.add('copied');

                setTimeout(() => {
                    button.textContent = originalText;
                    button.classList.remove('copied');
                }, 2000);
            }).catch(err => {
                console.error('Failed to copy:', err);
                button.textContent = 'Failed';
                setTimeout(() => {
                    button.textContent = 'Copy';
                }, 2000);
            });
        }
    </script>
</body>
</html>
